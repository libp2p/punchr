{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Database Connection\n",
    "\n",
    "In this section, we go over connecting to the database from this jupyter notebook. First of all you need to install all necessary tools and dependencies by running:\n",
    "\n",
    "```shell\n",
    "poetry install\n",
    "```\n",
    "\n",
    "in the `punchr/report` directory."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Imports"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sqlalchemy as sa\n",
    "import numpy as np\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as mtick\n",
    "from matplotlib.lines import Line2D\n",
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import pycountry as pyc\n",
    "import seaborn as sns\n",
    "import functools as ft\n",
    "from datetime import datetime\n",
    "from dataclasses import dataclass\n",
    "from typing import Set, List"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Initialize Connection"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "conn = sa.create_engine(\"postgresql://punchr:password@localhost:5432/punchr\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Add multi address transport column\n",
    "\n",
    "A typical multi address looks like this: `/ip4/1.2.3.4/udp/62505/quic` . To be able to easily filter by/query for specific transports we add another column to the `multi_addresses` table that adds the transport of the multi address."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "query = \"\"\"\n",
    "CREATE TYPE transport AS ENUM ('unknown', 'tcp', 'quic', 'ws');\n",
    "\n",
    "ALTER TABLE multi_addresses ADD COLUMN transport transport;\n",
    "\n",
    "UPDATE multi_addresses SET\n",
    "    transport = CASE\n",
    "        WHEN maddr LIKE '%%/tcp/%%' THEN\n",
    "            'tcp'::transport\n",
    "        WHEN maddr LIKE '%%/quic%%' THEN\n",
    "            'quic'::transport\n",
    "        WHEN maddr LIKE '%%/ws%%' THEN\n",
    "            'ws'::transport\n",
    "        ELSE\n",
    "            'unknown'::transport\n",
    "    END;\n",
    "\n",
    "ALTER TABLE multi_addresses ALTER COLUMN transport SET NOT NULL;\n",
    "\"\"\"\n",
    "conn.execute(query)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Dissect protocol filter column\n",
    "\n",
    "The server restricts the transport protocol and IP version use of the local client and remote peers. This allows for distinct analyses which combination works better than the other. The relevant code is [here](https://github.com/libp2p/punchr/blob/4d2343ff01f2250a7b88314dde0fa2e6ca9a1775/cmd/server/grpc.go#L143). The server send out the desired Multiaddress codecs to be used:\n",
    "\n",
    "```go\n",
    "if r < 0.15 {\n",
    "\tresp.Protocols = []int32{multiaddr.P_IP4, multiaddr.P_TCP}\n",
    "} else if r < 0.3 {\n",
    "\tresp.Protocols = []int32{multiaddr.P_IP4, multiaddr.P_QUIC}\n",
    "} else if r < 0.45 {\n",
    "\tresp.Protocols = []int32{multiaddr.P_IP6, multiaddr.P_TCP}\n",
    "} else if r < 0.6 {\n",
    "\tresp.Protocols = []int32{multiaddr.P_IP6, multiaddr.P_QUIC}\n",
    "} else {\n",
    "\tresp.Protocols = []int32{}\n",
    "}\n",
    "```\n",
    "\n",
    "40% of the hole punches wonâ€™t filter at all. The remaining 60% are evenly distributed between the four combinations of TCP/QUIC and IPv4/IPv6.\n",
    "\n",
    "Since the database saves the codec integer values we map them to something easier to work with. Namely the `transport` type and a version number for IP:"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "query = f\"\"\"\n",
    "ALTER TABLE hole_punch_results ADD COLUMN ip_version_filter INT;\n",
    "ALTER TABLE hole_punch_results ADD COLUMN transport_filter transport;\n",
    "\n",
    "UPDATE hole_punch_results\n",
    "SET ip_version_filter = CASE\n",
    "        WHEN 4 = ANY(protocol_filters) THEN 4\n",
    "        WHEN 41 = ANY(protocol_filters) THEN 6\n",
    "    END,\n",
    "    transport_filter = CASE\n",
    "        WHEN 6 = ANY(protocol_filters) THEN 'tcp'::transport\n",
    "        WHEN 460 = ANY(protocol_filters) THEN 'quic'::transport\n",
    "    END;\n",
    "\"\"\"\n",
    "conn.execute(query)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Add information about which IP Version and Transport were actually used\n",
    "\n",
    "The following query adds two new columns to the `hole_punch_results` table. Namely:\n",
    "\n",
    "- `local_ip_version_used` - The IP version that was used for the hole punch. If `NULL` IPv4 and IPv6 were used. If `4`, the hole punch was only attempted with IPv4 (from the local side). This can either be because the filter was requesting the hole punch to be performed with IPv4 or the peer only supported IPv4 addresses. Same applies for IPv6. In this case the column would say `6`\n",
    "- `local_transport_used` - The transport protocol that was used for the hole punch from the client side (local). If `NULL`, `tcp` and `quic` were used. If only e.g., `tcp`, only the `tcp` transport was tried. Same applies for `quic`.\n",
    "\n",
    "The following query applies the protocol filter to the listen addresses. If the number of listen addresses after filtering is > 0 then the filter was applied and only these remaining addresses were used. This means we update the `local_ip_version_used` and `local_transport_used` columns to the values of the protocol filters."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "query = f\"\"\"\n",
    "ALTER TABLE hole_punch_results ADD COLUMN local_ip_version_used INT;\n",
    "ALTER TABLE hole_punch_results ADD COLUMN local_transport_used transport;\n",
    "\"\"\"\n",
    "conn.execute(query)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "query = f\"\"\"\n",
    "UPDATE hole_punch_results outer_hpr\n",
    "SET local_ip_version_used = subquery.ip_version_filter,\n",
    "    local_transport_used = subquery.transport_filter\n",
    "FROM (\n",
    "    SELECT\n",
    "        inner_hpr.id,\n",
    "        inner_hpr.ip_version_filter,\n",
    "        inner_hpr.transport_filter\n",
    "    FROM hole_punch_results inner_hpr\n",
    "        INNER JOIN multi_addresses_sets mas on inner_hpr.listen_multi_addresses_set_id = mas.id\n",
    "        CROSS JOIN unnest(mas.multi_addresses_ids) listen_multi_addresses(id)\n",
    "        INNER JOIN multi_addresses ma ON ma.id = listen_multi_addresses.id\n",
    "    WHERE ma.is_public\n",
    "      AND NOT ma.is_relay\n",
    "      AND inner_hpr.ip_version_filter = family(ma.addr)\n",
    "      AND inner_hpr.transport_filter = ma.transport\n",
    "    GROUP BY inner_hpr.id, inner_hpr.ip_version_filter, inner_hpr.transport_filter\n",
    " ) AS subquery\n",
    "WHERE subquery.id = outer_hpr.id;\n",
    "\"\"\"\n",
    "conn.execute(query)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Now, it could be that the above filtering \"removed\" all addresses from a peer. In this case it could still be that only e.g., a certain IP version was used because the peer has only e.g., IPv4 addresses. This is what we try to find out with the following query."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "query = f\"\"\"\n",
    "UPDATE hole_punch_results outer_hpr\n",
    "SET local_ip_version_used = subquery.ip_version_used\n",
    "FROM (\n",
    "    SELECT\n",
    "        inner_hpr.id,\n",
    "        min(family(ma.addr)) ip_version_used\n",
    "    FROM hole_punch_results inner_hpr\n",
    "        INNER JOIN multi_addresses_sets mas on inner_hpr.listen_multi_addresses_set_id = mas.id\n",
    "        CROSS JOIN unnest(mas.multi_addresses_ids) listen_multi_addresses(id)\n",
    "        INNER JOIN multi_addresses ma ON ma.id = listen_multi_addresses.id\n",
    "    WHERE inner_hpr.local_ip_version_used IS NULL\n",
    "        AND ma.is_public AND NOT ma.is_relay\n",
    "    GROUP BY inner_hpr.id\n",
    "    HAVING count(DISTINCT family(ma.addr)) = 1\n",
    ") AS subquery\n",
    "WHERE subquery.id = outer_hpr.id;\n",
    "\"\"\"\n",
    "conn.execute(query)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "The same reasoning as above for the transport column:"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "query = f\"\"\"\n",
    "UPDATE hole_punch_results outer_hpr\n",
    "SET local_transport_used = subquery.transport_used\n",
    "FROM (\n",
    "    SELECT\n",
    "        inner_hpr.id,\n",
    "        min(ma.transport) transport_used\n",
    "    FROM hole_punch_results inner_hpr\n",
    "        INNER JOIN multi_addresses_sets mas on inner_hpr.listen_multi_addresses_set_id = mas.id\n",
    "        CROSS JOIN unnest(mas.multi_addresses_ids) listen_multi_addresses(id)\n",
    "        INNER JOIN multi_addresses ma ON ma.id = listen_multi_addresses.id\n",
    "    WHERE inner_hpr.local_transport_used IS NULL\n",
    "        AND ma.is_public AND NOT ma.is_relay\n",
    "    GROUP BY inner_hpr.id\n",
    "    HAVING count(DISTINCT ma.transport) = 1\n",
    ") AS subquery\n",
    "WHERE subquery.id = outer_hpr.id;\n",
    "\"\"\"\n",
    "conn.execute(query)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Add field that Indicates if the Client has a Public Address"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "query = f\"\"\"\n",
    "-- ALTER TABLE hole_punch_results ADD COLUMN local_has_public_addr BOOLEAN;\n",
    "\n",
    "UPDATE hole_punch_results outer_hpr\n",
    "SET local_has_public_addr = subquery.has_public_addr\n",
    "FROM (\n",
    "\tSELECT inner_hpr.id, TRUE = ANY(array_agg(ma.is_public)) has_public_addr\n",
    "    FROM hole_punch_results inner_hpr\n",
    "        INNER JOIN multi_addresses_sets mas on inner_hpr.listen_multi_addresses_set_id = mas.id\n",
    "        CROSS JOIN unnest(mas.multi_addresses_ids) listen_multi_addresses(id)\n",
    "        INNER JOIN multi_addresses ma ON ma.id = listen_multi_addresses.id\n",
    "    GROUP BY inner_hpr.id\n",
    " ) AS subquery\n",
    "WHERE subquery.id = outer_hpr.id;\n",
    "\n",
    "ALTER TABLE hole_punch_results ALTER COLUMN local_has_public_addr SET NOT NULL;\n",
    "\"\"\"\n",
    "conn.execute(query)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Add remote used transport columns to hole punch attempts table\n",
    "\n",
    "The protocol/IP filter also applies to the remote peer. However, here we store only the already filtered version. So no need to detect it ourselves."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "query = f\"\"\"\n",
    "ALTER TABLE hole_punch_attempt ADD COLUMN remote_ip_version_used INT;\n",
    "ALTER TABLE hole_punch_attempt ADD COLUMN remote_transport_used transport;\n",
    "\n",
    "UPDATE hole_punch_attempt hpa\n",
    "SET remote_ip_version_used = subquery.remote_ip_verion\n",
    "FROM (\n",
    "    SELECT hpa.id, min(family(ma.addr)) remote_ip_verion\n",
    "    FROM hole_punch_attempt hpa\n",
    "        INNER JOIN hole_punch_attempt_x_multi_addresses hpaxma on hpa.id = hpaxma.hole_punch_attempt\n",
    "        INNER JOIN multi_addresses ma on hpaxma.multi_address_id = ma.id\n",
    "    GROUP BY hpa.id\n",
    "    HAVING count(DISTINCT family(ma.addr)) = 1\n",
    ") AS subquery\n",
    "WHERE hpa.id = subquery.id;\n",
    "\n",
    "\n",
    "UPDATE hole_punch_attempt hpa\n",
    "SET remote_transport_used = subquery.remote_transport\n",
    "FROM (\n",
    "    SELECT hpa.id, min(ma.transport) remote_transport\n",
    "    FROM hole_punch_attempt hpa\n",
    "        INNER JOIN hole_punch_attempt_x_multi_addresses hpaxma on hpa.id = hpaxma.hole_punch_attempt\n",
    "        INNER JOIN multi_addresses ma on hpaxma.multi_address_id = ma.id\n",
    "    GROUP BY hpa.id\n",
    "    HAVING count(DISTINCT ma.transport) = 1\n",
    ") AS subquery\n",
    "WHERE hpa.id = subquery.id\n",
    "\"\"\"\n",
    "conn.execute(query)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Deduplicate Clients Table\n",
    "\n",
    "If there are clients that were used anonymously AND with a registered version we only want to know the registered authorization.\n",
    "\n",
    "We completely exclude rust from our consideration according to [@mxinden](https://github.com/mxinden)."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "query = f\"\"\"\n",
    "CREATE TABLE cleaned_clients AS (\n",
    "    -- get all non rust clients that have multiple authorizations and only use the non 'anonymous' ones\n",
    "    SELECT outer_clients.*\n",
    "    FROM clients outer_clients\n",
    "    WHERE outer_clients.peer_id IN (\n",
    "        SELECT c.peer_id\n",
    "        FROM clients c\n",
    "            INNER JOIN authorizations a on a.id = c.authorization_id\n",
    "            INNER JOIN peers p ON c.peer_id = p.id\n",
    "        WHERE p.agent_version NOT LIKE '%%rust%%'\n",
    "        GROUP BY c.peer_id\n",
    "        HAVING count(c.authorization_id) > 1\n",
    "    ) AND outer_clients.authorization_id IN (\n",
    "        SELECT a.id\n",
    "        FROM authorizations a\n",
    "        WHERE a.id = outer_clients.authorization_id\n",
    "          AND a.username != 'anonymous'\n",
    "    )\n",
    "    -- get all non rust clients that have a single authorization\n",
    "    UNION ALL\n",
    "    SELECT outer_clients.*\n",
    "    FROM clients outer_clients\n",
    "    WHERE outer_clients.peer_id IN (\n",
    "        SELECT c.peer_id\n",
    "        FROM clients c\n",
    "            INNER JOIN authorizations a on a.id = c.authorization_id\n",
    "            INNER JOIN peers p ON c.peer_id = p.id\n",
    "        WHERE p.agent_version NOT LIKE '%%rust%%'\n",
    "        GROUP BY c.peer_id\n",
    "        HAVING count(c.authorization_id) = 1\n",
    "    )\n",
    "    -- get all non rust clients that have multiple 'anonymous' authorization and select only a single one\n",
    "    UNION ALL\n",
    "    SELECT min(outer_clients.id), outer_clients.peer_id, min(outer_clients.authorization_id)\n",
    "    FROM clients outer_clients\n",
    "    WHERE outer_clients.peer_id IN (\n",
    "        SELECT c.peer_id\n",
    "        FROM clients c\n",
    "            INNER JOIN authorizations a on a.id = c.authorization_id\n",
    "            INNER JOIN peers p ON c.peer_id = p.id\n",
    "        WHERE p.agent_version NOT LIKE '%%rust%%' AND a.username = 'anonymous'\n",
    "        GROUP BY c.peer_id\n",
    "        HAVING count(c.authorization_id) > 1\n",
    "    )\n",
    "    GROUP BY outer_clients.peer_id\n",
    ");\n",
    "\"\"\"\n",
    "conn.execute(query)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Add authorization ID to hole punch results"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "query = f\"\"\"\n",
    "-- ALTER TABLE hole_punch_results ADD COLUMN authorization_id INT;\n",
    "\n",
    "UPDATE hole_punch_results outer_hpr\n",
    "SET authorization_id = subquery.authorization_id\n",
    "FROM (\n",
    "    SELECT inner_hpr.id, c.authorization_id\n",
    "    FROM hole_punch_results inner_hpr\n",
    "        INNER JOIN cleaned_clients c ON inner_hpr.local_id = c.peer_id\n",
    "     ) AS subquery\n",
    "WHERE outer_hpr.id = subquery.id;\n",
    "\"\"\"\n",
    "conn.execute(query)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Detect Individual Networks\n",
    "\n",
    "The following can happen\n",
    "\n",
    "- Peer A is online with IP4_1 and IP6_1\n",
    "- Then Peer A is online with IP4_1 and IP6_2\n",
    "- Then Peer A is online only with IP6_2\n",
    "- Then Peer A is online only with IP4_1\n",
    "\n",
    "With \"being online\" I mean that the \"listen\" multi addresses contain the respective IP4, IP6 addresses. In the above example Peer A was in the same network the whole time. This is what we want to detect."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Public Network Grouping"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "query = f\"\"\"\n",
    "SELECT array_agg(DISTINCT ma.addr) addrs\n",
    "FROM multi_addresses_sets mas\n",
    "    LEFT JOIN LATERAL unnest(mas.multi_addresses_ids) AS listen_multi_addresses(id) ON true\n",
    "    INNER JOIN multi_addresses ma ON ma.id = listen_multi_addresses.id\n",
    "WHERE ma.is_public\n",
    "GROUP BY mas.id, ma.asn\n",
    "\"\"\"\n",
    "df = pd.read_sql_query(query, con=conn)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "local_addr_sets = []\n",
    "lookup = {}\n",
    "for idx, row in df.iterrows():\n",
    "    new_addrs = row[\"addrs\"]\n",
    "\n",
    "    found_idxs = []\n",
    "    for new_addr in new_addrs:\n",
    "        if new_addr in lookup:\n",
    "            found_idxs += [lookup[new_addr]]\n",
    "\n",
    "    if len(found_idxs) > 1:\n",
    "        new_addr_set = set({})\n",
    "        for found_idx in found_idxs:\n",
    "            if local_addr_sets[found_idx] is None:\n",
    "                continue\n",
    "            new_addr_set = new_addr_set.union(local_addr_sets[found_idx])\n",
    "            local_addr_sets[found_idx] = None\n",
    "\n",
    "        for new_addr in new_addrs:\n",
    "            new_addr_set.add(new_addr)\n",
    "\n",
    "        for addr in new_addr_set:\n",
    "            lookup[addr] = len(local_addr_sets)\n",
    "\n",
    "        local_addr_sets += [new_addr_set]\n",
    "    elif len(found_idxs) == 1:\n",
    "        for new_addr in new_addrs:\n",
    "            local_addr_sets[found_idxs[0]].add(new_addr)\n",
    "    elif len(found_idxs) == 0:\n",
    "        addr_set = set({})\n",
    "        for new_addr in new_addrs:\n",
    "            addr_set.add(new_addr)\n",
    "            lookup[new_addr] = len(local_addr_sets)\n",
    "        local_addr_sets += [addr_set]\n",
    "local_addr_sets = list(filter(lambda addr_set: addr_set is not None, local_addr_sets))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "query = f\"\"\"\n",
    "SELECT array_agg(DISTINCT ma.addr) addrs\n",
    "FROM hole_punch_attempt_x_multi_addresses hpaxma\n",
    "    INNER JOIN multi_addresses ma ON ma.id = hpaxma.multi_address_id\n",
    "WHERE ma.is_public\n",
    "GROUP BY hpaxma.hole_punch_attempt, ma.asn\n",
    "\"\"\"\n",
    "df = pd.read_sql_query(query, con=conn)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "remote_addr_sets = []\n",
    "lookup = {}\n",
    "for idx, row in df.iterrows():\n",
    "    if idx % 10_000 == 0:\n",
    "        print(idx)\n",
    "\n",
    "    new_addrs = row[\"addrs\"]\n",
    "\n",
    "    found_idxs = []\n",
    "    for new_addr in new_addrs:\n",
    "        if new_addr in lookup:\n",
    "            found_idxs += [lookup[new_addr]]\n",
    "\n",
    "    if len(found_idxs) > 1:\n",
    "        new_addr_set = set({})\n",
    "        for found_idx in found_idxs:\n",
    "            if remote_addr_sets[found_idx] is None:\n",
    "                continue\n",
    "            new_addr_set = new_addr_set.union(remote_addr_sets[found_idx])\n",
    "            remote_addr_sets[found_idx] = None\n",
    "\n",
    "        for new_addr in new_addrs:\n",
    "            new_addr_set.add(new_addr)\n",
    "\n",
    "        for addr in new_addr_set:\n",
    "            lookup[addr] = len(remote_addr_sets)\n",
    "\n",
    "        remote_addr_sets += [new_addr_set]\n",
    "    elif len(found_idxs) == 1:\n",
    "        for new_addr in new_addrs:\n",
    "            remote_addr_sets[found_idxs[0]].add(new_addr)\n",
    "    elif len(found_idxs) == 0:\n",
    "        addr_set = set({})\n",
    "        for new_addr in new_addrs:\n",
    "            addr_set.add(new_addr)\n",
    "            lookup[new_addr] = len(remote_addr_sets)\n",
    "        remote_addr_sets += [addr_set]\n",
    "remote_addr_sets = list(filter(lambda addr_set: addr_set is not None, remote_addr_sets))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "query = f\"\"\"\n",
    "CREATE TABLE mapping (\n",
    "    public_network_id INT,\n",
    "    addr TEXT\n",
    ")\n",
    "\"\"\"\n",
    "conn.execute(query)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "query = f\"\"\"\n",
    "INSERT INTO mapping (public_network_id, addr) VALUES\n",
    "\"\"\"\n",
    "for i, addr_set in enumerate(local_addr_sets + remote_addr_sets):\n",
    "    for addr in addr_set:\n",
    "        query += f\"({i}, '{addr}'),\\n\"\n",
    "\n",
    "query = query.rstrip()\n",
    "query = query.rstrip(\",\")\n",
    "query = query + \";\"\n",
    "conn.execute(query)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "conn.execute(\"ALTER TABLE multi_addresses ADD COLUMN public_network_id INT\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "query = f\"\"\"\n",
    "UPDATE multi_addresses mm\n",
    "SET public_network_id = subquery.public_network_id\n",
    "FROM (\n",
    "    SELECT ma.id, m.public_network_id\n",
    "    FROM multi_addresses ma\n",
    "        INNER JOIN mapping m ON m.addr::INET = ma.addr\n",
    "    ) AS subquery\n",
    "WHERE mm.id = subquery.id\n",
    "\"\"\"\n",
    "conn.execute(query)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "conn.execute(\"DROP TABLE mapping\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Merge With Private IP addresses"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "query = f\"\"\"\n",
    "WITH cte AS (\n",
    "    -- Group all private IP addresses per hole punch result\n",
    "    SELECT\n",
    "        hpr.id hole_punch_result_id,\n",
    "        hpr.authorization_id,\n",
    "        ma.public_network_id,\n",
    "        ma.asn,\n",
    "        ma.country,\n",
    "        (\n",
    "            SELECT array_agg(DISTINCT ma.addr ORDER BY ma.addr)\n",
    "            FROM hole_punch_results inner_hpr\n",
    "                INNER JOIN multi_addresses_sets mas ON mas.id = inner_hpr.listen_multi_addresses_set_id\n",
    "                CROSS JOIN unnest(mas.multi_addresses_ids) AS listen_multi_addresses(id)\n",
    "                INNER JOIN multi_addresses ma on ma.id = listen_multi_addresses.id\n",
    "            WHERE\n",
    "              NOT ma.is_public\n",
    "              AND ma.addr != '127.0.0.1'\n",
    "              AND ma.addr != '::1'\n",
    "              AND ma.addr != '172.17.0.1'\n",
    "              AND inner_hpr.authorization_id IS NOT NULL\n",
    "              AND inner_hpr.id = hpr.id\n",
    "        ) private_addrs\n",
    "    FROM hole_punch_results hpr\n",
    "        INNER JOIN multi_addresses_sets mas ON mas.id = hpr.listen_multi_addresses_set_id\n",
    "        CROSS JOIN unnest(mas.multi_addresses_ids) AS listen_multi_addresses(id)\n",
    "        INNER JOIN multi_addresses ma on ma.id = listen_multi_addresses.id\n",
    "    WHERE ma.is_public AND hpr.authorization_id IS NOT NULL AND hpr.local_has_public_addr\n",
    "    GROUP BY hpr.id, hpr.authorization_id, ma.public_network_id, ma.asn, ma.country\n",
    "), cte_2 AS (\n",
    "    -- Merge all private IP addresses by client (authorization ID), public network and ASN.\n",
    "    SELECT\n",
    "        cte.authorization_id,\n",
    "        cte.public_network_id,\n",
    "        cte.asn,\n",
    "        cte.country,\n",
    "        array_remove(array_agg(DISTINCT private_addrs.id ORDER BY private_addrs.id), NULL) AS private_addrs,\n",
    "        array_agg(DISTINCT cte.hole_punch_result_id) hole_punch_result_ids\n",
    "    FROM cte\n",
    "        LEFT JOIN LATERAL unnest(cte.private_addrs) private_addrs(id) ON true\n",
    "    GROUP BY cte.authorization_id, cte.public_network_id, cte.asn, cte.country\n",
    ")\n",
    "-- now, public_addrs contains all public networks that have the same set of private addrs in the same ASN\n",
    "SELECT\n",
    "    cte_2.private_addrs,\n",
    "    cte_2.asn,\n",
    "    cte_2.country,\n",
    "    array_agg(DISTINCT cte_2.public_network_id ORDER BY cte_2.public_network_id) public_addrs,\n",
    "    array_agg(DISTINCT hole_punch_results.id) AS hole_punch_result_ids,\n",
    "    array_length(array_remove(cte_2.private_addrs, NULL), 1) IS NULL is_vpn\n",
    "FROM cte_2, unnest(cte_2.hole_punch_result_ids) hole_punch_results(id)\n",
    "GROUP BY cte_2.private_addrs, cte_2.asn, cte_2.country\n",
    "\"\"\"\n",
    "df = pd.read_sql_query(query, con=conn)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "len(df)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class Network:\n",
    "    private_addrs: Set[str]\n",
    "    public_addrs: Set[str]\n",
    "    hole_punch_result_ids: Set[int]\n",
    "    asn: int\n",
    "    country: str\n",
    "    is_vpn: bool"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "networks: List[Network] = []\n",
    "lookup = {}\n",
    "for idx, row in df.iterrows():\n",
    "\n",
    "    new_network = Network(set(row[\"private_addrs\"]), set(row[\"public_addrs\"]), set(row[\"hole_punch_result_ids\"]), row[\"asn\"], row[\"country\"], row[\"is_vpn\"])\n",
    "\n",
    "    found_idxs = []\n",
    "    for new_addr in new_network.private_addrs:\n",
    "        if f\"{new_network.country}|{new_network.asn}|{new_addr}\" in lookup:\n",
    "            found_idxs += [lookup[f\"{new_network.country}|{new_network.asn}|{new_addr}\"]]\n",
    "\n",
    "    if len(found_idxs) > 1:\n",
    "        for found_idx in found_idxs:\n",
    "            if networks[found_idx] is None:\n",
    "                continue\n",
    "\n",
    "            new_network.private_addrs = new_network.private_addrs.union(networks[found_idx].private_addrs)\n",
    "            new_network.hole_punch_result_ids = new_network.hole_punch_result_ids.union(networks[found_idx].hole_punch_result_ids)\n",
    "            networks[found_idx] = None\n",
    "\n",
    "        for addr in new_network.private_addrs:\n",
    "            lookup[f\"{new_network.country}|{new_network.asn}|{addr}\"] = len(networks)\n",
    "\n",
    "        networks += [new_network]\n",
    "    elif len(found_idxs) == 1:\n",
    "        for new_addr in new_network.private_addrs:\n",
    "            networks[found_idxs[0]].private_addrs.add(new_addr)\n",
    "        for ids in new_network.hole_punch_result_ids:\n",
    "            networks[found_idxs[0]].hole_punch_result_ids.add(ids)\n",
    "    elif len(found_idxs) == 0:\n",
    "        for new_addr in new_network.private_addrs:\n",
    "            lookup[f\"{new_network.country}|{new_network.asn}|{new_addr}\"] = len(networks)\n",
    "        networks += [new_network]\n",
    "networks = list(filter(lambda network: network is not None, networks))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [
    {
     "data": {
      "text/plain": "<sqlalchemy.engine.cursor.LegacyCursorResult at 0x2a5e791e0>"
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = f\"\"\"\n",
    "CREATE TABLE mapping (\n",
    "    network_id INT,\n",
    "    hole_punch_result_id INT\n",
    ")\n",
    "\"\"\"\n",
    "conn.execute(query)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [],
   "source": [
    "query = f\"\"\"\n",
    "INSERT INTO mapping (network_id, hole_punch_result_id) VALUES\n",
    "\"\"\"\n",
    "for i, network in enumerate(networks):\n",
    "    for hpr_id in network.hole_punch_result_ids:\n",
    "        query += f\"({i}, '{hpr_id}'),\\n\"\n",
    "\n",
    "query = query.rstrip()\n",
    "query = query.rstrip(\",\")\n",
    "query = query + \";\"\n",
    "conn.execute(query);"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "outputs": [
    {
     "data": {
      "text/plain": "<sqlalchemy.engine.cursor.LegacyCursorResult at 0x2a5e79bd0>"
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conn.execute(\"ALTER TABLE hole_punch_results ADD COLUMN network_id INT\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "outputs": [
    {
     "data": {
      "text/plain": "<sqlalchemy.engine.cursor.LegacyCursorResult at 0x2a797d480>"
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = f\"\"\"\n",
    "UPDATE hole_punch_results hpr\n",
    "SET network_id = subquery.network_id\n",
    "FROM (\n",
    "    SELECT h.id, min(m.network_id) network_id\n",
    "    FROM hole_punch_results h\n",
    "        INNER JOIN mapping m ON m.hole_punch_result_id = h.id\n",
    "    GROUP BY h.id\n",
    "    HAVING count(DISTINCT m.network_id) = 1\n",
    "    ) AS subquery\n",
    "WHERE hpr.id = subquery.id\n",
    "\"\"\"\n",
    "conn.execute(query)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "outputs": [
    {
     "data": {
      "text/plain": "<sqlalchemy.engine.cursor.LegacyCursorResult at 0x2a797cd60>"
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conn.execute(\"DROP TABLE mapping\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "outputs": [
    {
     "data": {
      "text/plain": "<sqlalchemy.engine.cursor.LegacyCursorResult at 0x2a5e79f00>"
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = f\"\"\"\n",
    "CREATE TABLE networks (\n",
    "    network_id INT,\n",
    "    is_vpn BOOLEAN\n",
    ")\n",
    "\"\"\"\n",
    "conn.execute(query)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "outputs": [],
   "source": [
    "query = f\"\"\"\n",
    "INSERT INTO networks (network_id, is_vpn) VALUES\n",
    "\"\"\"\n",
    "for i, network in enumerate(networks):\n",
    "    is_vpn = \"TRUE\" if network.is_vpn else \"FALSE\"\n",
    "    query += f\"({i}, '{is_vpn}'),\\n\"\n",
    "\n",
    "query = query.rstrip()\n",
    "query = query.rstrip(\",\")\n",
    "query = query + \";\"\n",
    "conn.execute(query);"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Port Mappings\n",
    "\n",
    "## Extract external IP address"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "query = f\"\"\"\n",
    "ALTER TABLE port_mappings ADD COLUMN ip_address INET;\n",
    "\n",
    "UPDATE port_mappings pm\n",
    "SET ip_address = split_part(pm.addr, ':', 1)::INET\n",
    "\"\"\"\n",
    "conn.execute(query)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "query = f\"\"\"\n",
    "ALTER TABLE port_mappings ADD COLUMN is_public BOOLEAN;\n",
    "ALTER TABLE port_mappings ADD COLUMN is_cloud INT;\n",
    "ALTER TABLE port_mappings ADD COLUMN country TEXT;\n",
    "ALTER TABLE port_mappings ADD COLUMN continent TEXT;\n",
    "ALTER TABLE port_mappings ADD COLUMN asn INT;\n",
    "\n",
    "UPDATE port_mappings pm -- does take ages to complete\n",
    "SET is_public = ma.is_public,\n",
    "    is_cloud = ma.is_cloud,\n",
    "    country = ma.country,\n",
    "    continent = ma.continent,\n",
    "    asn = ma.asn\n",
    "FROM multi_addresses ma\n",
    "WHERE pm.ip_address = ma.addr\n",
    "\"\"\"\n",
    "conn.execute(query)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Latency Measurements"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "query = \"\"\"\n",
    "UPDATE latency_measurements lm\n",
    "SET rtts = coalesce((SELECT array_agg(rtts.rtt) FROM unnest(lm.rtts) rtts(rtt) WHERE rtts.rtt >= 0), '{}'::FLOAT[]);\n",
    "\n",
    "\n",
    "UPDATE latency_measurements lm\n",
    "SET rtt_avg = coalesce((SELECT avg(rtts.rtt) FROM unnest(lm.rtts) rtts(rtt)), -1),\n",
    "    rtt_std = coalesce((SELECT stddev(rtts.rtt) FROM unnest(lm.rtts) rtts(rtt)), -1),\n",
    "    rtt_min = coalesce((SELECT min(rtts.rtt) FROM unnest(lm.rtts) rtts(rtt)), -1),\n",
    "    rtt_max = coalesce((SELECT max(rtts.rtt) FROM unnest(lm.rtts) rtts(rtt)), -1)\n",
    "\"\"\"\n",
    "conn.execute(query)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
